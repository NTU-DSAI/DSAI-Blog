"use strict";(self.webpackChunkntu_dsai_github_io=self.webpackChunkntu_dsai_github_io||[]).push([[113],{3905:function(e,t,n){n.d(t,{Zo:function(){return c},kt:function(){return m}});var o=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,o,r=function(e,t){if(null==e)return{};var n,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=o.createContext({}),u=function(e){var t=o.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},c=function(e){var t=u(e.components);return o.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},p=o.forwardRef((function(e,t){var n=e.components,r=e.mdxType,a=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),p=u(n),m=r,h=p["".concat(l,".").concat(m)]||p[m]||d[m]||a;return n?o.createElement(h,i(i({ref:t},c),{},{components:n})):o.createElement(h,i({ref:t},c))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=n.length,i=new Array(a);i[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,i[1]=s;for(var u=2;u<a;u++)i[u]=n[u];return o.createElement.apply(null,i)}return o.createElement.apply(null,n)}p.displayName="MDXCreateElement"},320:function(e,t,n){n.r(t),n.d(t,{assets:function(){return c},contentTitle:function(){return l},default:function(){return m},frontMatter:function(){return s},metadata:function(){return u},toc:function(){return d}});var o=n(3117),r=n(102),a=(n(7294),n(3905)),i=["components"],s={id:"sc4001-neural-networks-and-deep-learning",slug:"sc4001-neural-networks-and-deep-learning",sidebar_position:12,title:"SC4001 Neural Networks and Deep Learning",description:"Study of various deep network systems",keywords:["neural network","deep learning","scse","ntu","course","module"]},l=void 0,u={unversionedId:"Module-Review/MPEs/sc4001-neural-networks-and-deep-learning",id:"Module-Review/MPEs/sc4001-neural-networks-and-deep-learning",title:"SC4001 Neural Networks and Deep Learning",description:"Study of various deep network systems",source:"@site/docs/Module-Review/MPEs/SC4001 Neural Networks and Deep Learning.md",sourceDirName:"Module-Review/MPEs",slug:"/Module-Review/MPEs/sc4001-neural-networks-and-deep-learning",permalink:"/docs/Module-Review/MPEs/sc4001-neural-networks-and-deep-learning",editUrl:"https://github.com/NTU-DSAI/NTU-DSAI.github.io/tree/master/docs/Module-Review/MPEs/SC4001 Neural Networks and Deep Learning.md",tags:[],version:"current",sidebarPosition:12,frontMatter:{id:"sc4001-neural-networks-and-deep-learning",slug:"sc4001-neural-networks-and-deep-learning",sidebar_position:12,title:"SC4001 Neural Networks and Deep Learning",description:"Study of various deep network systems",keywords:["neural network","deep learning","scse","ntu","course","module"]},sidebar:"tutorialSidebar",previous:{title:"MH4501 Multivariate Analysis",permalink:"/docs/Module-Review/MPEs/mh4501-multivariate-analysis"},next:{title:"SC4002 Natural Language Processing",permalink:"/docs/Module-Review/MPEs/sc4002-natural-language-processing"}},c={},d=[{value:"Course Summary",id:"course-summary",level:2},{value:"Workload",id:"workload",level:2},{value:"Projects",id:"projects",level:2},{value:"Things to take note of",id:"things-to-take-note-of",level:2},{value:"Conclusion",id:"conclusion",level:2}],p={toc:d};function m(e){var t=e.components,n=(0,r.Z)(e,i);return(0,a.kt)("wrapper",(0,o.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",{id:"course-summary"},"Course Summary"),(0,a.kt)("p",null,"This course teaches students about Neural Networks and how they can be used to solve problems. The course is taught by Prof Jagath for the first half and Prof Chen Change Loy for the second. Prof Loy works at MMLab@NTU and is a highly cited researcher, who is able to provide deep insights about the content that he teaches in the second half as parts of it pertain to his research areas. The topics taught include:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Neurons and Activation Functions"),(0,a.kt)("li",{parentName:"ol"},"Regression and Classification"),(0,a.kt)("li",{parentName:"ol"},"Neuron Layers"),(0,a.kt)("li",{parentName:"ol"},"Deep Networks"),(0,a.kt)("li",{parentName:"ol"},"Model Selection"),(0,a.kt)("li",{parentName:"ol"},"Convolutional Neural Networks (CNNs)",(0,a.kt)("ol",{parentName:"li"},(0,a.kt)("li",{parentName:"ol"},"Pointwise Convolution"),(0,a.kt)("li",{parentName:"ol"},"Depthwise Convolution"),(0,a.kt)("li",{parentName:"ol"},"Batch Normalisation"),(0,a.kt)("li",{parentName:"ol"},"Transfer Learning"),(0,a.kt)("li",{parentName:"ol"},"Data Augmentation"))),(0,a.kt)("li",{parentName:"ol"},"Recurrent Neural Networks (RNNs)",(0,a.kt)("ol",{parentName:"li"},(0,a.kt)("li",{parentName:"ol"},"Elman and Jordan Type"),(0,a.kt)("li",{parentName:"ol"},"LSTM"))),(0,a.kt)("li",{parentName:"ol"},"Attention",(0,a.kt)("ol",{parentName:"li"},(0,a.kt)("li",{parentName:"ol"},"Visual Attention"),(0,a.kt)("li",{parentName:"ol"},"Seq-2-Seq"),(0,a.kt)("li",{parentName:"ol"},"Transformers"))),(0,a.kt)("li",{parentName:"ol"},"Autoencoders"),(0,a.kt)("li",{parentName:"ol"},"Generative Adversarial Networks (GANs)")),(0,a.kt)("h2",{id:"workload"},"Workload"),(0,a.kt)("p",null,"The workload for this course is fairly managable but does get heavier towards the end of the semester due to the project. Prof Jagath provides all the tutorial answers with sample code for your reference so that you can go back and take a look at how he arrived at his answer. There are no tutorials for the second half but examples are provided as well."),(0,a.kt)("h2",{id:"projects"},"Projects"),(0,a.kt)("p",null,"There are 2 projects in this course. The first is to design some simple neural networks to solve basic classification and regression tasks. This is pretty straightforward to do and should not take very long if done correctly. There might be some confusion regarding the questions as they change the dataset every year so the TAs are available to clarify any doubts."),(0,a.kt)("p",null,"The second project is more tedious as it is self driven and you have to pick a project from a given list or make up one of your own. You can make models in any field of deep learning as long as you demonstrate that you can come up with a project of sufficient depth and a model of sufficient complexity."),(0,a.kt)("h2",{id:"things-to-take-note-of"},"Things to take note of"),(0,a.kt)("p",null,"The final for this exam does require ",(0,a.kt)("strong",{parentName:"p"},"A LOT")," of manual matrix multiplication so do get familiar with using your calculator and keying in the values. You will not have enough time to finish the paper so do strategise how you approach it. Questions for the second half of the course are more qualitative so it is easier to score there. Do also strategise which other modules you are going to take with this one as being in a project heavy semester will take up way more time than you imagine as training models is a slow process."),(0,a.kt)("div",{className:"admonition admonition-warning alert alert--danger"},(0,a.kt)("div",{parentName:"div",className:"admonition-heading"},(0,a.kt)("h5",{parentName:"div"},(0,a.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,a.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},(0,a.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M5.05.31c.81 2.17.41 3.38-.52 4.31C3.55 5.67 1.98 6.45.9 7.98c-1.45 2.05-1.7 6.53 3.53 7.7-2.2-1.16-2.67-4.52-.3-6.61-.61 2.03.53 3.33 1.94 2.86 1.39-.47 2.3.53 2.27 1.67-.02.78-.31 1.44-1.13 1.81 3.42-.59 4.78-3.42 4.78-5.56 0-2.84-2.53-3.22-1.25-5.61-1.52.13-2.03 1.13-1.89 2.75.09 1.08-1.02 1.8-1.86 1.33-.67-.41-.66-1.19-.06-1.78C8.18 5.31 8.68 2.45 5.05.32L5.03.3l.02.01z"}))),"warning")),(0,a.kt)("div",{parentName:"div",className:"admonition-content"},(0,a.kt)("p",{parentName:"div"},"Even though the Final Exam for this course is open book, ",(0,a.kt)("strong",{parentName:"p"},"DO NOT PRINT ALL THE SLIDES"),". You will be wasting paper, your money and your time flipping through the notes to find the piece of information you are looking for. Be smart and write down essential information on a cheatsheet ",(0,a.kt)("strong",{parentName:"p"},"no more than 6 pages (3 sheets of paper)")," and remember where the information is written. The course is called Deep ",(0,a.kt)("em",{parentName:"p"},"Learning")," for a reason \ud83e\udd26\u200d\u2642\ufe0f."))),(0,a.kt)("h2",{id:"conclusion"},"Conclusion"),(0,a.kt)("p",null,"This course is a must take for all DSAI students as it teaches you all the important aspects of neural networks as well as introduces you to multiple network models that are used to solve specific problems."))}m.isMDXComponent=!0}}]);