"use strict";(self.webpackChunkntu_dsai_github_io=self.webpackChunkntu_dsai_github_io||[]).push([[6795],{3905:(e,t,r)=>{r.d(t,{Zo:()=>c,kt:()=>h});var n=r(7294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function l(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function i(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},o=Object.keys(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var s=n.createContext({}),u=function(e){var t=n.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):l(l({},t),e)),r},c=function(e){var t=u(e.components);return n.createElement(s.Provider,{value:t},e.children)},d="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),d=u(r),m=a,h=d["".concat(s,".").concat(m)]||d[m]||p[m]||o;return r?n.createElement(h,l(l({ref:t},c),{},{components:r})):n.createElement(h,l({ref:t},c))}));function h(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=r.length,l=new Array(o);l[0]=m;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i[d]="string"==typeof e?e:a,l[1]=i;for(var u=2;u<o;u++)l[u]=r[u];return n.createElement.apply(null,l)}return n.createElement.apply(null,r)}m.displayName="MDXCreateElement"},2093:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>s,contentTitle:()=>l,default:()=>p,frontMatter:()=>o,metadata:()=>i,toc:()=>u});var n=r(7462),a=(r(7294),r(3905));const o={id:"mh2100-calculus-3",slug:"mh2100-calculus-3",sidebar_position:1,title:"MH2100 Calculus 3"},l=void 0,i={unversionedId:"Module-Review/Y3S1/mh2100-calculus-3",id:"Module-Review/Y3S1/mh2100-calculus-3",title:"MH2100 Calculus 3",description:"Course Summary",source:"@site/docs/Module-Review/Y3S1/MH2100 Calculus 3.md",sourceDirName:"Module-Review/Y3S1",slug:"/Module-Review/Y3S1/mh2100-calculus-3",permalink:"/docs/Module-Review/Y3S1/mh2100-calculus-3",draft:!1,editUrl:"https://github.com/NTU-DSAI/NTU-DSAI.github.io/tree/master/docs/Module-Review/Y3S1/MH2100 Calculus 3.md",tags:[],version:"current",lastUpdatedBy:"dependabot[bot]",lastUpdatedAt:1722907977,formattedLastUpdatedAt:"Aug 6, 2024",sidebarPosition:1,frontMatter:{id:"mh2100-calculus-3",slug:"mh2100-calculus-3",sidebar_position:1,title:"MH2100 Calculus 3"},sidebar:"tutorialSidebar",previous:{title:"SC3000 Artificial Intelligence",permalink:"/docs/Module-Review/Y2S2/sc3000-artificial-intelligence"},next:{title:"SC4000 Machine Learning",permalink:"/docs/Module-Review/Y3S1/sc4000-machine-learning"}},s={},u=[{value:"Course Summary",id:"course-summary",level:2},{value:"Workload",id:"workload",level:2},{value:"Projects",id:"projects",level:2},{value:"Things to take note of",id:"things-to-take-note-of",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u},d="wrapper";function p(e){let{components:t,...r}=e;return(0,a.kt)(d,(0,n.Z)({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",{id:"course-summary"},"Course Summary"),(0,a.kt)("p",null,"This course covers calculus in 3 dimensions and thus includes content on Vectors, Vector fields and Coordinate Change.\nIt is taught by Gary Greeves which is a student favourite professor as he is articulate and knowledgeable.\nThe content covered is:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Vectors"),(0,a.kt)("li",{parentName:"ol"},"Limits"),(0,a.kt)("li",{parentName:"ol"},"Continuity"),(0,a.kt)("li",{parentName:"ol"},"Partial Derivatives"),(0,a.kt)("li",{parentName:"ol"},"Tangent Planes"),(0,a.kt)("li",{parentName:"ol"},"Differentiability"),(0,a.kt)("li",{parentName:"ol"},"Linear Approximations"),(0,a.kt)("li",{parentName:"ol"},"Directional Derivative"),(0,a.kt)("li",{parentName:"ol"},"Gradient Vector"),(0,a.kt)("li",{parentName:"ol"},"Critical Points"),(0,a.kt)("li",{parentName:"ol"},"Lagrange Multipliers"),(0,a.kt)("li",{parentName:"ol"},"Coordinate Change"),(0,a.kt)("li",{parentName:"ol"},"Plane Transformation"),(0,a.kt)("li",{parentName:"ol"},"Line Integrals"),(0,a.kt)("li",{parentName:"ol"},"Surface Integrals",(0,a.kt)("ol",{parentName:"li"},(0,a.kt)("li",{parentName:"ol"},"Scalar Field"),(0,a.kt)("li",{parentName:"ol"},"Vector Field"))),(0,a.kt)("li",{parentName:"ol"},"Curl"),(0,a.kt)("li",{parentName:"ol"},"Stoke's Theorem")),(0,a.kt)("h2",{id:"workload"},"Workload"),(0,a.kt)("p",null,"The workload is generally manageable but the lecutres might seem a bit content heavy.\nOnce understood they are pretty easy to just apply since it's just mathematics but it can get tedious."),(0,a.kt)("h2",{id:"projects"},"Projects"),(0,a.kt)("p",null,"There are no projects for this as this is a pure mathematics module.\nThere are 2 graded assignments and some online quizzes throughout the module so do be prepared for that."),(0,a.kt)("h2",{id:"things-to-take-note-of"},"Things to take note of"),(0,a.kt)("p",null,"The prof uses an online tool to check your knowledge during the lectures and this counts towards an attendance mark so please do attend lectures for this.\nIt also helps to solidify your understanding of the content taught."),(0,a.kt)("h2",{id:"conclusion"},"Conclusion"),(0,a.kt)("p",null,"A pretty challenging but necessary module to take, espeically as a ML student, as this is how stochastic gradient descent works and thus it is very important for your understanding."))}p.isMDXComponent=!0}}]);